{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install apache_beam mwparserfromhell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## public libraries\n",
    "from datasets import load_dataset\n",
    "\n",
    "## local libraries\n",
    "from gpt_utils import (\n",
    "    get_encoder_decoder_size,\n",
    "    text_to_tv_tensors,\n",
    "    get_batch\n",
    ")\n",
    "from attention_decoder import AttentionModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikipedia (/Users/paul/.cache/huggingface/datasets/wikipedia/20220301.simple/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ee497a5720461bae90490febe89a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wiki_raw = load_dataset(\"wikipedia\", \"20220301.simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'text'],\n",
       "        num_rows: 205328\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215900536\n",
      "\n",
      "April is the fourth month of the year in the Julian and Gregorian calendars, and comes between March and May. It is one of four months to have 30 days.\n",
      "\n",
      "April always begins on the same day of week as July, and additionally, January in leap years. April always ends on the same day of the week as December.\n",
      "\n",
      "April's flowers are the Sweet Pea and Daisy. Its birthstone is the diamond. The meaning of the diamond is innocence.\n",
      "\n",
      "The Month \n",
      "\n",
      "April comes between March and May, making it the fourth month of the year. It also comes first in the year out of the four months that have 30 days, as June, September and November are later in the year.\n",
      "\n",
      "April begins on the same day of the week as July every year and on the same day of the week as January in leap years. April ends on the same day of the week as December every year, as each other's last days are exactly 35 weeks (245 days) apart.\n",
      "\n",
      "In common years, April starts on the same day of the week as October of the previous year, and in leap years, M\n"
     ]
    }
   ],
   "source": [
    "wiki_text_blob = '\\n\\n'.join(wiki_raw['train']['text'])\n",
    "print(len(wiki_text_blob))\n",
    "print()\n",
    "print(wiki_text_blob[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\n !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##When sorted, low-numbered codes seem to be more \"normal\"\n",
    "normal_chars = ''.join(sorted(list(set(wiki_text_blob)))[0:97])\n",
    "normal_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 sec ish\n",
    "wiki_text_blob_clean = ''.join([x for x in wiki_text_blob if x in normal_chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.997293827931951"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep 99.7% of chars. great.\n",
    "len(wiki_text_blob_clean)/len(wiki_text_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "encode, decode, vocab_size = get_encoder_decoder_size(wiki_text_blob_clean)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([215316272]) torch.int64\n",
      "tensor([35, 82, 84, 75, 78,  2, 75, 85,  2, 86, 74, 71,  2, 72, 81, 87, 84, 86,\n",
      "        74,  2, 79, 81, 80, 86, 74,  2, 81, 72,  2, 86, 74, 71,  2, 91, 71, 67,\n",
      "        84,  2, 75, 80,  2, 86, 74, 71,  2, 44, 87, 78, 75, 67, 80,  2, 67, 80,\n",
      "        70,  2, 41, 84, 71, 73, 81, 84, 75, 67, 80,  2, 69, 67, 78, 71, 80, 70,\n",
      "        67, 84, 85, 14,  2, 67, 80, 70,  2, 69, 81, 79, 71, 85,  2, 68, 71, 86,\n",
      "        89, 71, 71, 80,  2, 47, 67, 84, 69, 74])\n"
     ]
    }
   ],
   "source": [
    "train, validate = text_to_tv_tensors(wiki_text_blob_clean, encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_attn = AttentionModule(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(2.5938, grad_fn=<NllLossBackward>)\n",
      "100 tensor(2.4575, grad_fn=<NllLossBackward>)\n",
      "200 tensor(2.5328, grad_fn=<NllLossBackward>)\n",
      "300 tensor(2.3907, grad_fn=<NllLossBackward>)\n",
      "400 tensor(2.4390, grad_fn=<NllLossBackward>)\n",
      "500 tensor(2.4191, grad_fn=<NllLossBackward>)\n",
      "600 tensor(2.5385, grad_fn=<NllLossBackward>)\n",
      "700 tensor(2.4829, grad_fn=<NllLossBackward>)\n",
      "800 tensor(2.3916, grad_fn=<NllLossBackward>)\n",
      "900 tensor(2.5243, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.AdamW(m8_wiki.parameters(), lr=1e-3)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "optimizer = torch.optim.AdamW(m_attn.parameters(), lr=1e-3)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "for epoch in range(1000):\n",
    "  tx, ty = get_batch(train)\n",
    "\n",
    "  _, loss = m_attn(tx, ty)\n",
    "  optimizer.zero_grad(set_to_none=True)\n",
    "  if epoch%100 == 0:\n",
    "    print(epoch, loss)\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be or not to thip cask RIst 193 205\n",
      " 201953 pror ynspereanis. c Toustars anfercs Destttinings Mibeetgauet ohe he nasies  19\" is al ins sp and birias Baus nthisidanaret Hapstt and modd they and opece eont Glatrsh, Epanacals Jucky\n",
      "\n",
      "19\n",
      "is beostizitirebus) He brafitarar acmes of futrsg.\n",
      "thed Slony nose ahaus thing warves  greatson\" in atsthoos: ale  w'irnctar ding an F he wnoly\n",
      " Fremip 19 dider, Fury ath wishel whithiriflis wingl wifth the myypersana.\n",
      " Ref Mavatos, and uso Bucknealie San gies the sos cat su., Noat couf Das\"|216 T||||0|3)\n",
      "\n",
      "|0,) ane Rif Morcen, cantlerian sononters, Domun wos gillsst. It Janmong a Fe bules the  uffam Nese nand, ame pantie (69).16, 1984 omec.\n",
      " Ire Kulgzss wragite\n",
      " Therolt iflerd lidfies thehe wed by\n",
      " Haurgolst (ion 20).\n",
      "\n",
      "\n",
      "T638970 sthe rock the bHos, Vien canade 19  neccrdiners the the arrad wiccert bewhama\n",
      "Brrtht sham the Ssemenilus eland. Is in ofky Al Thaca i is by Pesrisingituge sonetu, ar cong ald Kude.\n",
      "\n",
      "\n",
      "Hugersi\n",
      "\n",
      "Jalainge Wimmad\n",
      "\n",
      "\n",
      "29< brck Mweresstsebsh kir Aw ace go\n"
     ]
    }
   ],
   "source": [
    "seed_raw = \"To be or not to \"\n",
    "seed = torch.tensor(encode(seed_raw)).view(1,-1)\n",
    "\n",
    "print(decode(m_attn.generate(seed, 1000)[0,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
