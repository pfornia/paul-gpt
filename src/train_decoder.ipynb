{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch==2.0.0 torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install apache_beam mwparserfromhell\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper scripts from github\n",
    "!pip install --force-reinstall https://github.com/pfornia/paul-gpt/blob/master/dist/paul_gpt-0.0.1-py3-none-any.whl?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## public libraries\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import datetime\n",
    "\n",
    "## local libraries\n",
    "from paul_gpt.gpt_utils import (\n",
    "# from gpt_utils import (    # LOCAL VERSION\n",
    "    get_encoder_decoder_size,\n",
    "    text_to_tv_tensors,\n",
    "    get_batch,\n",
    "    training_run,\n",
    "    test_forward_pass,\n",
    "    test_gen_text\n",
    ")\n",
    "from paul_gpt.attention_decoder import AttentionModule \n",
    "# from attention_decoder import AttentionModule  # LOCAL VERSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.set_default_device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_raw = load_dataset(\"wikipedia\", \"20220301.simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_text_blob = '\\n\\n'.join(wiki_raw['train']['text'])\n",
    "print(len(wiki_text_blob))\n",
    "print()\n",
    "print(wiki_text_blob[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##When sorted, low-numbered codes seem to be more \"normal\"\n",
    "normal_chars = ''.join(sorted(list(set(wiki_text_blob)))[0:97])\n",
    "normal_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 sec ish\n",
    "wiki_text_blob_clean = ''.join([x for x in wiki_text_blob if x in normal_chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep 99.7% of chars. great.\n",
    "len(wiki_text_blob_clean)/len(wiki_text_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode, decode, vocab_size = get_encoder_decoder_size(wiki_text_blob_clean)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate = text_to_tv_tensors(wiki_text_blob_clean, encode, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_attn = AttentionModule(vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_forward_pass(m_attn, validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../model_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_attn.load_state_dict(torch.load('../model_checkpoints/m_attn_2023-05-01_2200.pt', map_location=torch.device('cpu')))\n",
    "_ = m_attn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU = ~25s per epoch\n",
    "# GPU ~ 1s per epoch (or 15 min for 1000)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(\"Start: \" + str(now))\n",
    "training_run(m_attn, train, validate, num_epochs=1)\n",
    "print(\"Runtime: \" + str(datetime.datetime.now() - now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single inference on CPU: ~2min\n",
    "seed_raw = \"\"\"\n",
    "Tonight I'll dream, while I'm in bed\n",
    "When silly thoughts go through my head\n",
    "About the bugs and alphabet\n",
    "And when I wake tomorrow, I'll bet\n",
    "That you and I will walk together again\n",
    "\n",
    "I can tell that we are gonna be friends\n",
    "\"\"\"\n",
    "\n",
    "test_gen_text(m_attn, seed_raw, encode, decode, device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4000 epochs version on May 1st:\n",
    "\n",
    "[seed start]\n",
    "Tonight I'll dream, while I'm in bed\n",
    "When silly thoughts go through my head\n",
    "About the bugs and alphabet\n",
    "And when I wake tomorrow, I'll bet\n",
    "That you and I will walk together again\n",
    "\n",
    "I can tell that we are gonna be friends\n",
    "[seed end]\n",
    "\n",
    "Living people\n",
    "\n",
    "Germany dons the organisan languages\n",
    "Kolelly High Skyne (196821), where includes were lungth state.  It is in the soation of In of the Great Official Caugue is state.\n",
    " Living pound episode in Pardy's anguage is the player of Yaskorp Official Party.\n",
    " Brough Indias Republican: single 19 August 2012 of the UK airported Free of Indias.\n",
    "\n",
    "In a life original coast her reduced in Kasao, Bunitania and the Kambridgy.\n",
    " Many Lenso (d. 2016), Walkorfern, Texas and Punnus of Kapashi, Punja, Elizar Peak, Texas, France and Kambridgy, United Kapashi of travel. The population of Bus. All Quicka, Karal, Keapau, Virginian, Baki freemat Joe Lenson, Tenasyas, which did days not the Role and North Africa Empire from the AMD\n",
    " Game Operson and United Kingdom Awards\n",
    " Game The Flate of Carol.\n",
    " A contrown of the Game's Met Des of Game\n",
    " Fleenh Zalan, desting name ankwards\n",
    " Village Texas Cash be not ask lister\n",
    " Am When Hit Rebelle, control, cameral be usually singles standards (when two comparates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
